{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram Vocabulary: ['a', 'best', 'ever', 'funny', 'is', 'movie', 'soooo', 'this', 'what']\n",
      "1-gram BoW Vectors:\n",
      "Sentence 1: [0, 0, 0, 1, 1, 1, 1, 1, 0]\n",
      "Sentence 2: [1, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "Sentence 3: [0, 1, 1, 0, 0, 2, 0, 1, 0]\n",
      "\n",
      "==============================\n",
      "\n",
      "2-gram Vocabulary: ['a movie', 'best movie', 'ever this', 'is soooo', 'movie ever', 'movie is', 'soooo funny', 'this movie', 'what a']\n",
      "2-gram BoW Vectors:\n",
      "Sentence 1: [0, 0, 0, 1, 0, 1, 1, 1, 0]\n",
      "Sentence 2: [1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Sentence 3: [0, 1, 1, 0, 1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Simple tokenization: lowercase and remove non-alphanumeric (except spaces).\"\"\"\n",
    "    text = text.lower()\n",
    "    return re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "def create_unigram_bow(sentences):\n",
    "    \"\"\"Creates a 1-gram BoW representation.\"\"\"\n",
    "    all_tokens = []\n",
    "    tokenized_sentences = [tokenize(s) for s in sentences]\n",
    "    for tokens in tokenized_sentences:\n",
    "        all_tokens.extend(tokens)\n",
    "    vocabulary = sorted(list(set(all_tokens)))\n",
    "    bow_vectors = []\n",
    "    for tokens in tokenized_sentences:\n",
    "        vector = [tokens.count(word) for word in vocabulary]\n",
    "        bow_vectors.append(vector)\n",
    "    return vocabulary, bow_vectors\n",
    "\n",
    "def create_bigram_bow(sentences):\n",
    "    \"\"\"Creates a 2-gram BoW representation.\"\"\"\n",
    "    all_bigrams = []\n",
    "    bigram_sentences = []\n",
    "    for s in sentences:\n",
    "        tokens = tokenize(s)\n",
    "        bigrams = [\" \".join(tokens[i:i+2]) for i in range(len(tokens) - 1)]\n",
    "        bigram_sentences.append(bigrams)\n",
    "        all_bigrams.extend(bigrams)\n",
    "    vocabulary = sorted(list(set(all_bigrams)))\n",
    "    bow_vectors = []\n",
    "    for bigrams in bigram_sentences:\n",
    "        vector = [bigrams.count(ngram) for ngram in vocabulary]\n",
    "        bow_vectors.append(vector)\n",
    "    return vocabulary, bow_vectors\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sentences = [\n",
    "        \"This movie is SOOOO funny!!!!\",\n",
    "        \"What a movie!\",\n",
    "        \"best movie ever!!!!! this movie\"\n",
    "    ]\n",
    "\n",
    "    # 1-gram BoW\n",
    "    unigram_vocab, unigram_vectors = create_unigram_bow(sentences)\n",
    "    print(\"1-gram Vocabulary:\", unigram_vocab)\n",
    "    print(\"1-gram BoW Vectors:\")\n",
    "    for i, vector in enumerate(unigram_vectors):\n",
    "        print(f\"Sentence {i+1}: {vector}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "    # 2-gram BoW\n",
    "    bigram_vocab, bigram_vectors = create_bigram_bow(sentences)\n",
    "    print(\"2-gram Vocabulary:\", bigram_vocab)\n",
    "    print(\"2-gram BoW Vectors:\")\n",
    "    for i, vector in enumerate(bigram_vectors):\n",
    "        print(f\"Sentence {i+1}: {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz to aclImdb_v1.tar.gz...\n",
      "Download complete.\n",
      "Extracting aclImdb_v1.tar.gz to ....\n",
      "Extraction complete.\n",
      "Removing .\\aclImdb\\train\\unsup...\n",
      "Removed unlabeled data directory.\n",
      "\n",
      "--- README Content ---\n",
      "Large Movie Review Dataset v1.0\n",
      "\n",
      "Overview\n",
      "\n",
      "This dataset contains movie reviews along with their associated binary\n",
      "sentiment polarity labels. It is intended to serve as a benchmark for\n",
      "sentiment classification. This document outlines how the dataset was\n",
      "gathered, and how to use the files provided. \n",
      "\n",
      "Dataset \n",
      "\n",
      "The core dataset contains 50,000 reviews split evenly into 25k train\n",
      "and 25k test sets. The overall distribution of labels is balanced (25k\n",
      "pos and 25k neg). We also include an additional 50,000 unlabeled\n",
      "documents for unsupervised learning. \n",
      "\n",
      "In the entire collection, no more than 30 reviews are allowed for any\n",
      "given movie because reviews for the same movie tend to have correlated\n",
      "ratings. Further, the train and test sets contain a disjoint set of\n",
      "movies, so no significant performance is obtained by memorizing\n",
      "movie-unique terms and their associated with observed labels.  In the\n",
      "labeled train/test sets, a negative review has a score <= 4 out of 10,\n",
      "and a positive review has a score >= 7 out of 10. Thus reviews with\n",
      "more neutral ratings are not included in the train/test sets. In the\n",
      "unsupervised set, reviews of any rating are included and there are an\n",
      "even number of reviews > 5 and <= 5.\n",
      "\n",
      "Files\n",
      "\n",
      "There are two top-level directories [train/, test/] corresponding to\n",
      "the training and test sets. Each contains [pos/, neg/] directories for\n",
      "the reviews with binary labels positive and negative. Within these\n",
      "directories, reviews are stored in text files named following the\n",
      "convention [[id]_[rating].txt] where [id] is a unique id and [rating] is\n",
      "the star rating for that review on a 1-10 scale. For example, the file\n",
      "[test/pos/200_8.txt] is the text for a positive-labeled test set\n",
      "example with unique id 200 and star rating 8/10 from IMDb. The\n",
      "[train/unsup/] directory has 0 for all ratings because the ratings are\n",
      "omitted for this portion of the dataset.\n",
      "\n",
      "We also include the IMDb URLs for each review in a separate\n",
      "[urls_[pos, neg, unsup].txt] file. A review with unique id 200 will\n",
      "have its URL on line 200 of this file. Due the ever-changing IMDb, we\n",
      "are unable to link directly to the review, but only to the movie's\n",
      "review page.\n",
      "\n",
      "In addition to the review text files, we include already-tokenized bag\n",
      "of words (BoW) features that were used in our experiments. These \n",
      "are stored in .feat files in the train/test directories. Each .feat\n",
      "file is in LIBSVM format, an ascii sparse-vector format for labeled\n",
      "data.  The feature indices in these files start from 0, and the text\n",
      "tokens corresponding to a feature index is found in [imdb.vocab]. So a\n",
      "line with 0:7 in a .feat file means the first word in [imdb.vocab]\n",
      "(the) appears 7 times in that review.\n",
      "\n",
      "LIBSVM page for details on .feat file format:\n",
      "http://www.csie.ntu.edu.tw/~cjlin/libsvm/\n",
      "\n",
      "We also include [imdbEr.txt] which contains the expected rating for\n",
      "each token in [imdb.vocab] as computed by (Potts, 2011). The expected\n",
      "rating is a good way to get a sense for the average polarity of a word\n",
      "in the dataset.\n",
      "\n",
      "Citing the dataset\n",
      "\n",
      "When using this dataset please cite our ACL 2011 paper which\n",
      "introduces it. This paper also contains classification results which\n",
      "you may want to compare against.\n",
      "\n",
      "\n",
      "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
      "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
      "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
      "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
      "  month     = {June},\n",
      "  year      = {2011},\n",
      "  address   = {Portland, Oregon, USA},\n",
      "  publisher = {Association for Computational Linguistics},\n",
      "  pages     = {142--150},\n",
      "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
      "}\n",
      "\n",
      "References\n",
      "\n",
      "Potts, Christopher. 2011. On the negativity of negation. In Nan Li and\n",
      "David Lutz, eds., Proceedings of Semantics and Linguistic Theory 20,\n",
      "636-659.\n",
      "\n",
      "Contact\n",
      "\n",
      "For questions/comments/corrections please contact Andrew Maas\n",
      "amaas@cs.stanford.edu\n",
      "\n",
      "Removed downloaded file: aclImdb_v1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "filename = \"aclImdb_v1.tar.gz\"\n",
    "extract_dir = \".\"  \n",
    "\n",
    "try:\n",
    "    print(f\"Downloading {url} to {filename}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()  \n",
    "    with open(filename, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "    print(f\"Extracting {filename} to {extract_dir}...\")\n",
    "    with tarfile.open(filename, \"r:gz\") as tar:\n",
    "        tar.extractall(path=extract_dir)\n",
    "    print(\"Extraction complete.\")\n",
    "\n",
    "    unsup_dir = os.path.join(extract_dir, \"aclImdb\", \"train\", \"unsup\")\n",
    "    if os.path.exists(unsup_dir):\n",
    "        print(f\"Removing {unsup_dir}...\")\n",
    "        shutil.rmtree(unsup_dir)\n",
    "        print(\"Removed unlabeled data directory.\")\n",
    "    else:\n",
    "        print(f\"Warning: {unsup_dir} not found.\")\n",
    "\n",
    "    readme_path = os.path.join(extract_dir, \"aclImdb\", \"README\")\n",
    "    if os.path.exists(readme_path):\n",
    "        with open(readme_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            print(\"\\n--- README Content ---\")\n",
    "            print(f.read())\n",
    "    else:\n",
    "        print(f\"Warning: {readme_path} not found.\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error downloading the file: {e}\")\n",
    "except tarfile.ReadError as e:\n",
    "    print(f\"Error opening or extracting the tar.gz file: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "finally:\n",
    "    # Clean up the downloaded archive\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "        print(f\"Removed downloaded file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF training data: (25000, 5000)\n",
      "Shape of TF-IDF test data: (25000, 5000)\n",
      "Number of features (vocabulary size): 5000\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "#paths to the training and testing data directories\n",
    "train_dir = './aclImdb/train'\n",
    "test_dir = './aclImdb/test'\n",
    "\n",
    "#IMDB movie review dataset\n",
    "train_review = load_files(train_dir, encoding='utf-8')\n",
    "x_train, y_train = train_review.data, train_review.target\n",
    "\n",
    "test_review = load_files(test_dir, encoding='utf-8')\n",
    "x_test, y_test = test_review.data, test_review.target\n",
    "\n",
    "#English stop words from NLTK\n",
    "stop_words_list = stopwords.words('english')\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    stop_words=stop_words_list,\n",
    "    max_features=5000  #the maximum vocabulary size\n",
    ")\n",
    "\n",
    "# Fit and transform the training data\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "\n",
    "# Transform the test data using the fitted vectorizer\n",
    "tfidf_test = tfidf_vectorizer.transform(x_test)\n",
    "\n",
    "print(\"Shape of TF-IDF training data:\", tfidf_train.shape)\n",
    "print(\"Shape of TF-IDF test data:\", tfidf_test.shape)\n",
    "print(\"Number of features (vocabulary size):\", len(tfidf_vectorizer.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.8810\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.88      0.88      0.88     12500\n",
      "         pos       0.88      0.88      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize a Logistic Regression model\n",
    "logistic_model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# Train the model on the TF-IDF training data\n",
    "logistic_model.fit(tfidf_train, y_train)\n",
    "\n",
    "# Make predictions on the TF-IDF test data\n",
    "y_pred = logistic_model.predict(tfidf_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=train_review.target_names)\n",
    "\n",
    "print(f\"Accuracy on the test set: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard TF-IDF Results:\n",
      "\n",
      "Document 1:\n",
      "a: 0.0000  best: 0.0000  ever: 0.0000  funny: 0.2197  i: 0.0000  is: 0.2197  movie: 0.0000  never: 0.0000  soooo: 0.2197  this: 0.0811  what: 0.0000  \n",
      "\n",
      "Document 2:\n",
      "a: 0.2197  best: 0.0000  ever: 0.0000  funny: 0.0000  i: 0.2197  is: 0.0000  movie: 0.0000  never: 0.2197  soooo: 0.0000  this: 0.0000  what: 0.2197  \n",
      "\n",
      "Document 3:\n",
      "a: 0.0000  best: 0.2197  ever: 0.2197  funny: 0.0000  i: 0.0000  is: 0.0000  movie: 0.0000  never: 0.0000  soooo: 0.0000  this: 0.0811  what: 0.0000  \n",
      "\n",
      "Scikit-learn TF-IDF Results:\n",
      "\n",
      "Document 1:\n",
      "a: 0.0000  best: 0.0000  ever: 0.0000  funny: 0.3386  i: 0.0000  is: 0.3386  movie: 0.2000  never: 0.0000  soooo: 0.3386  this: 0.2575  what: 0.0000  \n",
      "\n",
      "Document 2:\n",
      "a: 0.3386  best: 0.0000  ever: 0.0000  funny: 0.0000  i: 0.3386  is: 0.0000  movie: 0.2000  never: 0.3386  soooo: 0.0000  this: 0.0000  what: 0.3386  \n",
      "\n",
      "Document 3:\n",
      "a: 0.0000  best: 0.3386  ever: 0.3386  funny: 0.0000  i: 0.0000  is: 0.0000  movie: 0.4000  never: 0.0000  soooo: 0.0000  this: 0.2575  what: 0.0000  \n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Simple tokenization: lowercase and remove non-alphanumeric (except spaces).\"\"\"\n",
    "    text = text.lower()\n",
    "    return re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "def compute_tf(document):\n",
    "    \"\"\"Computes Term Frequency (TF) for a document.\"\"\"\n",
    "    tokens = tokenize(document)\n",
    "    tf_dict = {}\n",
    "    for token in tokens:\n",
    "        tf_dict[token] = tf_dict.get(token, 0) + 1\n",
    "    total_tokens = len(tokens)\n",
    "    for token in tf_dict:\n",
    "        tf_dict[token] /= total_tokens\n",
    "    return tf_dict\n",
    "\n",
    "def compute_idf(documents):\n",
    "    \"\"\"Computes Inverse Document Frequency (IDF) for a set of documents.\"\"\"\n",
    "    num_documents = len(documents)\n",
    "    word_doc_count = {}\n",
    "    for doc in documents:\n",
    "        tokens = set(tokenize(doc))  \n",
    "        for token in tokens:\n",
    "            word_doc_count[token] = word_doc_count.get(token, 0) + 1\n",
    "    \n",
    "    idf_dict = {}\n",
    "    for token, count in word_doc_count.items():\n",
    "        idf_dict[token] = math.log(num_documents / count)  # Standard IDF\n",
    "    return idf_dict\n",
    "\n",
    "def compute_sklearn_idf(documents):\n",
    "    \"\"\"Computes Inverse Document Frequency (IDF) as used in scikit-learn.\"\"\"\n",
    "    num_documents = len(documents)\n",
    "    word_doc_count = {}\n",
    "    for doc in documents:\n",
    "        tokens = set(tokenize(doc))\n",
    "        for token in tokens:\n",
    "            word_doc_count[token] = word_doc_count.get(token, 0) + 1\n",
    "    \n",
    "    idf_dict = {}\n",
    "    for token, count in word_doc_count.items():\n",
    "        idf_dict[token] = math.log((1 + num_documents) / (1 + count)) + 1 # Scikit-learn IDF\n",
    "    return idf_dict\n",
    "    \n",
    "\n",
    "def compute_tf_idf(document, idf_dict):\n",
    "    \"\"\"Computes TF-IDF for a document given the IDF dictionary.\"\"\"\n",
    "    tf_dict = compute_tf(document)\n",
    "    tf_idf_vector = {}\n",
    "    for token, tf_value in tf_dict.items():\n",
    "        if token in idf_dict:\n",
    "            tf_idf_vector[token] = tf_value * idf_dict[token]\n",
    "        else:\n",
    "            tf_idf_vector[token] = 0  # Handle unseen words\n",
    "    return tf_idf_vector\n",
    "\n",
    "def print_vector(title, vector, vocab):\n",
    "    \"\"\"Helper function to print TF-IDF vectors in a readable format.\"\"\"\n",
    "    print(f\"\\n{title}:\")\n",
    "    for word in vocab:\n",
    "        print(f\"{word}: {vector.get(word, 0):.4f}\", end=\"  \")\n",
    "    print()\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    documents = [\n",
    "        \"This movie is SOOOO funny!!!!\",\n",
    "        \"What a movie! I never\",\n",
    "        \"best movie ever!!!!! this movie\"\n",
    "    ]\n",
    "    \n",
    "    #Vocabulary\n",
    "    all_tokens = []\n",
    "    for doc in documents:\n",
    "        all_tokens.extend(tokenize(doc))\n",
    "    vocabulary = sorted(list(set(all_tokens)))\n",
    "    \n",
    "    # Standard TF-IDF Calculation\n",
    "    std_idf_dict = compute_idf(documents)\n",
    "    std_tf_idf_vectors = [compute_tf_idf(doc, std_idf_dict) for doc in documents]\n",
    "\n",
    "    print(\"Standard TF-IDF Results:\")\n",
    "    for i, vector in enumerate(std_tf_idf_vectors):\n",
    "        print_vector(f\"Document {i+1}\", vector, vocabulary)\n",
    "    \n",
    "    # Scikit-learn TF-IDF Calculation\n",
    "    sklearn_idf_dict = compute_sklearn_idf(documents)\n",
    "    sklearn_tf_idf_vectors = [compute_tf_idf(doc, sklearn_idf_dict) for doc in documents]\n",
    "    \n",
    "    print(\"\\nScikit-learn TF-IDF Results:\")\n",
    "    for i, vector in enumerate(sklearn_tf_idf_vectors):\n",
    "        print_vector(f\"Document {i+1}\", vector, vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a preprocessed review:\n",
      "['zero', 'day', 'leads', 'you', 'to', 'think', 'even', 'rethink', 'why', 'two', 'boysyoung', 'men', 'would', 'do', 'what', 'they', 'did', 'commit', 'mutual', 'suicide', 'via', 'slaughtering', 'their', 'classmates', 'it', 'captures', 'what', 'must', 'be', 'beyond', 'a', 'bizarre', 'mode', 'of', 'being', 'for', 'two', 'humans', 'who', 'have', 'decided', 'to', 'withdraw', 'from', 'common', 'civility', 'in', 'order', 'to', 'define', 'their', 'ownmutual', 'world', 'via', 'coupled', 'destructionbr', 'br', 'it', 'is', 'not', 'a', 'perfect', 'movie', 'but', 'given', 'what', 'moneytime', 'the', 'filmmaker', 'and', 'actors', 'had', 'it', 'is', 'a', 'remarkable', 'product', 'in', 'terms', 'of', 'explaining', 'the', 'motives', 'and', 'actions', 'of', 'the', 'two', 'young', 'suicidemurderers', 'it', 'is', 'better', 'than', 'elephant', 'in', 'terms', 'of', 'being', 'a', 'film', 'that', 'gets', 'under', 'our', 'rationalistic', 'skin', 'it', 'is', 'a', 'far', 'far', 'better', 'film', 'than', 'almost', 'anything', 'you', 'are', 'likely', 'to', 'see', 'br', 'br', 'flawed', 'but', 'honest', 'with', 'a', 'terrible', 'honesty']\n",
      "Number of preprocessed training reviews: 25000\n",
      "Number of preprocessed test reviews: 25000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by removing special characters, URLs,\n",
    "    lowercasing, and tokenizing it.\n",
    "    \"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove special characters \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = text.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def load_and_preprocess_imdb(data_dir):\n",
    "    \"\"\"\n",
    "    Loads the IMDB dataset from the specified directory and preprocesses\n",
    "    the text data.\n",
    "    \"\"\"\n",
    "    review_data = load_files(data_dir, encoding='utf-8')\n",
    "    preprocessed_reviews = [preprocess_text(review) for review in review_data.data]\n",
    "    return preprocessed_reviews, review_data.target\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess the IMDB training data\n",
    "    train_dir = './aclImdb/train' \n",
    "    preprocessed_train_reviews, y_train = load_and_preprocess_imdb(train_dir)\n",
    "    \n",
    "    # Print the first preprocessed review \n",
    "    print(\"Example of a preprocessed review:\")\n",
    "    print(preprocessed_train_reviews[0])\n",
    "    \n",
    "    # Print the number of preprocessed reviews\n",
    "    print(\"Number of preprocessed training reviews:\", len(preprocessed_train_reviews))\n",
    "    \n",
    "    #  Load and preprocess the IMDB test data.\n",
    "    test_dir = './aclImdb/test'\n",
    "    preprocessed_test_reviews, y_test = load_and_preprocess_imdb(test_dir)\n",
    "    \n",
    "    print(\"Number of preprocessed test reviews:\", len(preprocessed_test_reviews))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: gensim in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: wrapt in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Example of a preprocessed review:\n",
      "['zero', 'day', 'leads', 'you', 'to', 'think', 'even', 'rethink', 'why', 'two', 'boysyoung', 'men', 'would', 'do', 'what', 'they', 'did', 'commit', 'mutual', 'suicide', 'via', 'slaughtering', 'their', 'classmates', 'it', 'captures', 'what', 'must', 'be', 'beyond', 'a', 'bizarre', 'mode', 'of', 'being', 'for', 'two', 'humans', 'who', 'have', 'decided', 'to', 'withdraw', 'from', 'common', 'civility', 'in', 'order', 'to', 'define', 'their', 'ownmutual', 'world', 'via', 'coupled', 'destructionbr', 'br', 'it', 'is', 'not', 'a', 'perfect', 'movie', 'but', 'given', 'what', 'moneytime', 'the', 'filmmaker', 'and', 'actors', 'had', 'it', 'is', 'a', 'remarkable', 'product', 'in', 'terms', 'of', 'explaining', 'the', 'motives', 'and', 'actions', 'of', 'the', 'two', 'young', 'suicidemurderers', 'it', 'is', 'better', 'than', 'elephant', 'in', 'terms', 'of', 'being', 'a', 'film', 'that', 'gets', 'under', 'our', 'rationalistic', 'skin', 'it', 'is', 'a', 'far', 'far', 'better', 'film', 'than', 'almost', 'anything', 'you', 'are', 'likely', 'to', 'see', 'br', 'br', 'flawed', 'but', 'honest', 'with', 'a', 'terrible', 'honesty']\n",
      "Number of preprocessed training reviews: 25000\n",
      "\n",
      "Word2Vec model trained and saved as 'word2vec_imdb.model'\n",
      "\n",
      "Vector representation of 'movie':\n",
      "[ 1.30016683e-03 -9.80430283e-03  4.58776252e-03 -5.38222783e-04\n",
      "  6.33209571e-03  1.78347470e-03 -3.12979822e-03  7.75997294e-03\n",
      "  1.55466562e-03  5.52093989e-05 -4.61295387e-03 -8.45352374e-03\n",
      " -7.76683213e-03  8.67050979e-03 -8.92496016e-03  9.03471559e-03\n",
      " -9.28101782e-03 -2.76756298e-04 -1.90704700e-03 -8.93114600e-03\n",
      "  8.63005966e-03  6.77781366e-03  3.01943906e-03  4.83345287e-03\n",
      "  1.12190246e-04  9.42468084e-03  7.02128746e-03 -9.85372625e-03\n",
      " -4.43322072e-03 -1.29011157e-03  3.04772262e-03 -4.32395237e-03\n",
      "  1.44916656e-03 -7.84589909e-03  2.77807354e-03  4.70269192e-03\n",
      "  4.93731257e-03 -3.17570218e-03 -8.42704065e-03 -9.22061782e-03\n",
      " -7.22899451e-04 -7.32746487e-03 -6.81496272e-03  6.12000562e-03\n",
      "  7.17230327e-03  2.11741915e-03 -7.89940078e-03 -5.69898821e-03\n",
      "  8.05184525e-03  3.92084382e-03 -5.24047017e-03 -7.39190448e-03\n",
      "  7.71554711e-04  3.46375466e-03  2.07919348e-03  3.10080405e-03\n",
      " -5.62050007e-03 -9.88948625e-03 -7.02083716e-03  2.30308768e-04\n",
      "  4.61867917e-03  4.52630781e-03  1.87981245e-03  5.17067453e-03\n",
      " -1.05360748e-04  4.11416637e-03 -9.12324060e-03  7.70091172e-03\n",
      "  6.14747405e-03  5.12415636e-03  7.20666908e-03  8.43979698e-03\n",
      "  7.38695846e-04 -1.70386070e-03  5.18628338e-04 -9.31678060e-03\n",
      "  8.40621442e-03 -6.37993217e-03  8.42784252e-03 -4.24435502e-03\n",
      "  6.46842702e-04 -9.16416850e-03 -9.55856778e-03 -7.83681031e-03\n",
      " -7.73105631e-03  3.75581993e-04 -7.22646248e-03 -4.95021325e-03\n",
      " -5.27170673e-03 -4.28929785e-03  7.01231137e-03  4.82938997e-03\n",
      "  8.68277065e-03  7.09359162e-03 -5.69440611e-03  7.24079600e-03\n",
      " -9.29490291e-03 -2.58756871e-03 -7.75716640e-03  4.19260142e-03]\n",
      "\n",
      "Top 5 words similar to 'good':\n",
      "[('cindy', 0.3899497091770172), ('unknown', 0.3827079236507416), ('gandhis', 0.37549516558647156), ('despairbr', 0.37393832206726074), ('specimen', 0.3645557463169098)]\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn gensim nltk requests\n",
    "\n",
    "import re\n",
    "from sklearn.datasets import load_files\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "try:\n",
    "    from gensim.models import Word2Vec\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'gensim'])\n",
    "    from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by removing special characters, URLs,\n",
    "    lowercasing, and tokenizing it.\n",
    "    \"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove special characters \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = text.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def load_and_preprocess_imdb(data_dir):\n",
    "    \"\"\"\n",
    "    Loads the IMDB dataset from the specified directory and preprocesses\n",
    "    the text data.\n",
    "    \"\"\"\n",
    "    review_data = load_files(data_dir, encoding='utf-8')\n",
    "    preprocessed_reviews = [preprocess_text(review) for review in review_data.data]\n",
    "    return preprocessed_reviews, review_data.target\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess the IMDB training data\n",
    "    train_dir = './aclImdb/train' \n",
    "    preprocessed_train_reviews, y_train = load_and_preprocess_imdb(train_dir)\n",
    "    \n",
    "    # Print the first preprocessed review \n",
    "    print(\"Example of a preprocessed review:\")\n",
    "    print(preprocessed_train_reviews[0])\n",
    "    \n",
    "    # Print the number of preprocessed training reviews\n",
    "    print(\"Number of preprocessed training reviews:\", len(preprocessed_train_reviews))\n",
    "    \n",
    "    # Train Word2Vec model\n",
    "    vector_size = 100  # Dimensionality of the word vectors\n",
    "    window_size = 5    # Context window size\n",
    "    min_count = 5      # Minimum word frequency\n",
    "    epochs = 10       # Number of training iterations\n",
    "\n",
    "    model = Word2Vec(sentences=preprocessed_train_reviews,\n",
    "                     vector_size=vector_size,\n",
    "                     window=window_size,\n",
    "                     min_count=min_count,\n",
    "                     epochs=epochs,\n",
    "                     workers=-1)  \n",
    "\n",
    "    # Save the trained model \n",
    "    model.save(\"word2vec_imdb.model\")\n",
    "\n",
    "    print(\"\\nWord2Vec model trained and saved as 'word2vec_imdb.model'\")\n",
    "\n",
    "    #getting a word vector\n",
    "    try:\n",
    "        print(\"\\nVector representation of 'movie':\")\n",
    "        print(model.wv['movie'])\n",
    "    except KeyError:\n",
    "        print(\"\\nWord 'movie' not found in the vocabulary (min_count filter applied).\")\n",
    "\n",
    "    #finding similar words\n",
    "    try:\n",
    "        print(\"\\nTop 5 words similar to 'good':\")\n",
    "        similar_words = model.wv.most_similar('good', topn=5)\n",
    "        print(similar_words)\n",
    "    except KeyError:\n",
    "        print(\"\\nWord 'good' not found in the vocabulary (min_count filter applied).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word2Vec model trained and saved as 'word2vec_imdb.model'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 words similar to ['good']:\n",
      "cindy: 0.3899\n",
      "unknown: 0.3827\n",
      "gandhis: 0.3755\n",
      "despairbr: 0.3739\n",
      "specimen: 0.3646\n",
      "\n",
      "Top 5 words similar to ['bad']:\n",
      "parole: 0.3785\n",
      "artisans: 0.3751\n",
      "patrons: 0.3634\n",
      "patten: 0.3588\n",
      "mettle: 0.3563\n",
      "\n",
      "Top 5 words similar to ['movie', 'film']:\n",
      "unafraid: 0.4219\n",
      "coax: 0.3810\n",
      "fells: 0.3693\n",
      "bids: 0.3601\n",
      "loveless: 0.3570\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.datasets import load_files\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by removing special characters, URLs,\n",
    "    lowercasing, and tokenizing it.\n",
    "    \"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove special characters \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = text.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def load_and_preprocess_imdb(data_dir):\n",
    "    \"\"\"\n",
    "    Loads the IMDB dataset from the specified directory and preprocesses\n",
    "    the text data.\n",
    "    \"\"\"\n",
    "    review_data = load_files(data_dir, encoding='utf-8')\n",
    "    preprocessed_reviews = [preprocess_text(review) for review in review_data.data]\n",
    "    return preprocessed_reviews, review_data.target\n",
    "\n",
    "def visualize_word_vectors(model, words_to_visualize=None, n_components=2):\n",
    "    \"\"\"\n",
    "    Visualizes word vectors using t-SNE.\n",
    "\n",
    "    Args:\n",
    "        model: A trained Gensim Word2Vec model.\n",
    "        words_to_visualize:  A list of words to visualize. If None, visualize top occurring words.\n",
    "        n_components: The number of dimensions of the embedded space.\n",
    "    \"\"\"\n",
    "    \n",
    "    if words_to_visualize is None:\n",
    "        words_to_visualize = [word for word, _ in model.wv.most_common(50)]  \n",
    "    \n",
    "    # Filter words that exist in the model's vocabulary\n",
    "    words_to_visualize = [word for word in words_to_visualize if word in model.wv]\n",
    "        \n",
    "    if not words_to_visualize:\n",
    "        print(\"No words to visualize.  Check the vocabulary of the model and the words provided.\")\n",
    "        return\n",
    "        \n",
    "\n",
    "    vectors = np.array([model.wv[word] for word in words_to_visualize])\n",
    "    \n",
    "    if vectors.shape[0] < 2:\n",
    "        print(\"Need at least two words to visualize.\")\n",
    "        return\n",
    "\n",
    "    # \n",
    "    perplexity = min(30, vectors.shape[0] - 1) \n",
    "    tsne_model = TSNE(perplexity=perplexity, n_components=n_components, init='pca', n_iter=5000, random_state=23)\n",
    "    vectors_tsne = tsne_model.fit_transform(vectors)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))  \n",
    "    ax.scatter(vectors_tsne[:, 0], vectors_tsne[:, 1])\n",
    "    for i, word in enumerate(words_to_visualize):\n",
    "        ax.annotate(word, xy=(vectors_tsne[i, 0], vectors_tsne[i, 1]), fontsize=12)  \n",
    "    \n",
    "    if n_components == 2:\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "    plt.title(f'Word Vector Visualization using t-SNE ({n_components}D)')\n",
    "    plt.show()\n",
    "\n",
    "def find_similar_words(model, positive_words, topn=5):\n",
    "    \"\"\"\n",
    "    Finds and prints the most similar words to the given words using the Word2Vec model.\n",
    "\n",
    "    Args:\n",
    "        model: A trained Gensim Word2Vec model.\n",
    "        positive_words: A list of words to find similar words to.\n",
    "        topn: The number of similar words to return.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        similar_words = model.wv.most_similar(positive=positive_words, topn=topn)\n",
    "        print(f\"\\nTop {topn} words similar to {positive_words}:\")\n",
    "        for word, similarity in similar_words:\n",
    "            print(f\"{word}: {similarity:.4f}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"\\nWord(s) {positive_words} not found in the vocabulary: {e}\")\n",
    "    except AttributeError:\n",
    "        print(\"\\nModel does not have the attribute 'wv'.  Ensure it is a trained Word2Vec model.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess the IMDB training data\n",
    "    train_dir = './aclImdb/train'\n",
    "    preprocessed_train_reviews, y_train = load_and_preprocess_imdb(train_dir)\n",
    "\n",
    "    # Train Word2Vec model\n",
    "    vector_size = 100\n",
    "    window_size = 5\n",
    "    min_count = 5\n",
    "    epochs = 10\n",
    "\n",
    "    model = Word2Vec(sentences=preprocessed_train_reviews,\n",
    "                     vector_size=vector_size,\n",
    "                     window=window_size,\n",
    "                     min_count=min_count,\n",
    "                     epochs=epochs,\n",
    "                     workers=-1)\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save(\"word2vec_imdb.model\")\n",
    "    print(\"\\nWord2Vec model trained and saved as 'word2vec_imdb.model'\")\n",
    "    \n",
    "    # Visualize word vectors\n",
    "    visualize_word_vectors(model, words_to_visualize=['good', 'bad', 'movie', 'film', 'great', 'terrible', 'actor', 'actress'], n_components=2)\n",
    "    \n",
    "    # Find similar words\n",
    "    find_similar_words(model, positive_words=['good'], topn=5)\n",
    "    find_similar_words(model, positive_words=['bad'], topn=5)\n",
    "    find_similar_words(model, positive_words=['movie', 'film'], topn=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Using Word2Vec trained on IMDB ---\n",
      "\n",
      "--- Logistic Regression (Word2Vec - IMDB) ---\n",
      "Accuracy: 0.6471\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64     12500\n",
      "           1       0.64      0.66      0.65     12500\n",
      "\n",
      "    accuracy                           0.65     25000\n",
      "   macro avg       0.65      0.65      0.65     25000\n",
      "weighted avg       0.65      0.65      0.65     25000\n",
      "\n",
      "\n",
      "--- 2. Using pre-trained GloVe embeddings ---\n",
      "Loaded pre-trained GloVe vectors from C:\\Users\\Admin\\Downloads\\glove.6B\\glove.6B.100d.txt\n",
      "\n",
      "--- Logistic Regression (GloVe) ---\n",
      "Accuracy: 0.7972\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80     12500\n",
      "           1       0.80      0.79      0.79     12500\n",
      "\n",
      "    accuracy                           0.80     25000\n",
      "   macro avg       0.80      0.80      0.80     25000\n",
      "weighted avg       0.80      0.80      0.80     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by removing special characters, URLs,\n",
    "    lowercasing, and tokenizing it.\n",
    "    \"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove special characters \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Tokenize the text\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def load_and_preprocess_imdb(data_dir):\n",
    "    \"\"\"\n",
    "    Loads the IMDB dataset from the specified directory and preprocesses\n",
    "    the text data.\n",
    "    \"\"\"\n",
    "    review_data = load_files(data_dir, encoding='utf-8')\n",
    "    preprocessed_reviews = [preprocess_text(review) for review in review_data.data]\n",
    "    return preprocessed_reviews, review_data.target\n",
    "\n",
    "\n",
    "def get_word_vectors(model, preprocessed_reviews, vector_size):\n",
    "    \"\"\"\n",
    "    Get word vectors for each review in the dataset.  Averages the word vectors for each review.\n",
    "\n",
    "    Args:\n",
    "        model: A trained Gensim Word2Vec model (or KeyedVectors).\n",
    "        preprocessed_reviews: A list of preprocessed movie reviews (list of lists of tokens).\n",
    "        vector_size: The dimensionality of the word vectors.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (num_reviews, vector_size) containing the averaged word vectors for each review.\n",
    "    \"\"\"\n",
    "    review_vectors = []\n",
    "    for review in preprocessed_reviews:\n",
    "        word_vectors = []\n",
    "        for word in review:\n",
    "            try:\n",
    "                word_vector = model[word] \n",
    "                word_vectors.append(word_vector)\n",
    "            except KeyError:\n",
    "                # Word not in vocabulary, skip it\n",
    "                pass\n",
    "        if word_vectors:\n",
    "            # Average the word vectors for the review\n",
    "            review_vector = np.mean(word_vectors, axis=0)\n",
    "        else:\n",
    "            #\n",
    "            review_vector = np.zeros(vector_size)\n",
    "        review_vectors.append(review_vector)\n",
    "    return np.array(review_vectors)\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate_classifier(X_train, y_train, X_test, y_test, model_name=\"Logistic Regression\"):\n",
    "    \"\"\"\n",
    "    Trains a Logistic Regression classifier on the given data and evaluates its performance.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training data features.\n",
    "        y_train: Training data labels.\n",
    "        X_test: Test data features.\n",
    "        y_test: Test data labels.\n",
    "        model_name:  Name of the model for reporting\n",
    "    \"\"\"\n",
    "    # Train a Logistic Regression classifier\n",
    "    classifier = LogisticRegression(solver='liblinear', random_state=42, max_iter=500)  # Increased max_iter\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n--- {model_name} ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess the IMDB data\n",
    "    train_dir = './aclImdb/train'\n",
    "    test_dir = './aclImdb/test'\n",
    "    preprocessed_train_reviews, y_train = load_and_preprocess_imdb(train_dir)\n",
    "    preprocessed_test_reviews, y_test = load_and_preprocess_imdb(test_dir)\n",
    "\n",
    "    # --- 1. Using Word2Vec trained on IMDB ---\n",
    "    print(\"--- 1. Using Word2Vec trained on IMDB ---\")\n",
    "    # Train Word2Vec model on the IMDB training data\n",
    "    vector_size = 100\n",
    "    word2vec_model = Word2Vec(sentences=preprocessed_train_reviews,\n",
    "                                 vector_size=vector_size,\n",
    "                                 window=5,\n",
    "                                 min_count=5,\n",
    "                                 epochs=10,\n",
    "                                 workers=-1)\n",
    "\n",
    "    # Get Word2Vec vectors for the training and test sets\n",
    "    X_train_word2vec = get_word_vectors(word2vec_model.wv, preprocessed_train_reviews, vector_size)\n",
    "    X_test_word2vec = get_word_vectors(word2vec_model.wv, preprocessed_train_reviews, vector_size)\n",
    "\n",
    "    # Train and evaluate a classifier using the Word2Vec vectors\n",
    "    train_and_evaluate_classifier(X_train_word2vec, y_train, X_test_word2vec, y_test, model_name=\"Logistic Regression (Word2Vec - IMDB)\")\n",
    "\n",
    "\n",
    "    # --- 2. Using pre-trained GloVe embeddings ---\n",
    "    print(\"\\n--- 2. Using pre-trained GloVe embeddings ---\")\n",
    "    # Load pre-trained GloVe vectors (download if needed)\n",
    "    glove_file = r\"C:\\Users\\Admin\\Downloads\\glove.6B\\glove.6B.100d.txt\"\n",
    "    glove_model = None # Initialize glove_model\n",
    "    try:\n",
    "        glove_model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)\n",
    "        print(f\"Loaded pre-trained GloVe vectors from {glove_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: GloVe file '{glove_file}' not found. \")\n",
    "        \n",
    "\n",
    "    # Get GloVe vectors for the training and test sets\n",
    "    if glove_model: \n",
    "        X_train_glove = get_word_vectors(glove_model, preprocessed_train_reviews, vector_size)\n",
    "        X_test_glove = get_word_vectors(glove_model, preprocessed_test_reviews, vector_size)\n",
    "\n",
    "        # Train and evaluate a classifier using the GloVe vectors\n",
    "        train_and_evaluate_classifier(X_train_glove, y_train, X_test_glove, y_test, model_name=\"Logistic Regression (GloVe)\")\n",
    "    else:\n",
    "        print(\"GloVe model was not loaded, skipping GloVe training and evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
