{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "class ScratchSVMClassifier():\n",
    "    def __init__(self, num_iter=1000, lr=0.01, kernel='linear', \n",
    "                 gamma=1, theta0=0, degree=2, threshold=1e-5, verbose=False):\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.theta0 = theta0\n",
    "        self.degree = degree\n",
    "        self.threshold = threshold\n",
    "        self.verbose = verbose\n",
    "        self.n_support_vectors = None\n",
    "        self.X_sv = None\n",
    "        self.lam_sv = None\n",
    "        self.y_sv = None\n",
    "        self.b = 0\n",
    "\n",
    "    def _kernel_function(self, x1, x2):\n",
    "        \"\"\"Implement both linear and polynomial kernels\"\"\"\n",
    "        if self.kernel == 'linear':\n",
    "            return np.dot(x1, x2)\n",
    "        elif self.kernel == 'poly':\n",
    "            return (self.gamma * np.dot(x1, x2) + self.theta0) ** self.degree\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported kernel\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train SVM using gradient ascent on dual problem\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        lam = np.zeros(n_samples)\n",
    "        y_ = np.where(y <= 0, -1, 1)  # Convert to {-1, 1}\n",
    "\n",
    "        # Gradient ascent\n",
    "        for iter_ in range(self.iter):\n",
    "            for i in range(n_samples):\n",
    "                # Calculate gradient for each lambda\n",
    "                grad = 1 - sum(\n",
    "                    lam[j] * y_[i] * y_[j] * self._kernel_function(X[i], X[j])\n",
    "                    for j in range(n_samples)\n",
    "                )\n",
    "                lam[i] += self.lr * grad\n",
    "                lam[i] = max(lam[i], 0)  # Constraint: lambda >= 0\n",
    "\n",
    "        # Store support vectors\n",
    "        sv_idx = lam > self.threshold\n",
    "        self.n_support_vectors = np.sum(sv_idx)\n",
    "        self.X_sv = X[sv_idx]\n",
    "        self.lam_sv = lam[sv_idx].reshape(-1, 1)\n",
    "        self.y_sv = y_[sv_idx].reshape(-1, 1)\n",
    "\n",
    "        # Calculate bias (b)\n",
    "        if self.n_support_vectors > 0:\n",
    "            self.b = np.mean([\n",
    "                self.y_sv[i] - sum(\n",
    "                    self.lam_sv[j] * self.y_sv[j] * \n",
    "                    self._kernel_function(self.X_sv[i], self.X_sv[j])\n",
    "                    for j in range(self.n_support_vectors)\n",
    "                )\n",
    "                for i in range(self.n_support_vectors)\n",
    "            ])\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using support vectors\"\"\"\n",
    "        decisions = np.array([\n",
    "            self.b + sum(\n",
    "                self.lam_sv[j] * self.y_sv[j] * \n",
    "                self._kernel_function(x, self.X_sv[j])\n",
    "                for j in range(self.n_support_vectors)\n",
    "            )\n",
    "            for x in X\n",
    "        ])\n",
    "        return np.where(decisions >= 0, 1, 0)\n",
    "\n",
    "    def visualize_decision_boundary(self, X, y, resolution=0.02):\n",
    "        \"\"\"Visualize decision boundary with support vectors\"\"\"\n",
    "        # Create grid\n",
    "        x1_min, x1_max = X[:, 0].min()-1, X[:, 0].max()+1\n",
    "        x2_min, x2_max = X[:, 1].min()-1, X[:, 1].max()+1\n",
    "        xx, yy = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                            np.arange(x2_min, x2_max, resolution))\n",
    "        \n",
    "        # Predict and plot\n",
    "        Z = self.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.coolwarm, s=20)\n",
    "        \n",
    "        # Plot support vectors\n",
    "        if self.X_sv is not None:\n",
    "            plt.scatter(self.X_sv[:,0], self.X_sv[:,1],\n",
    "                       facecolors='none', edgecolors='k',\n",
    "                       s=100, linewidths=1.5, label=\"Support Vectors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "####\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, \n",
    "                          n_clusters_per_class=1, random_state=42)\n",
    "\n",
    "# Linear kernel\n",
    "linear_svm = ScratchSVMClassifier(kernel='linear', verbose=True)\n",
    "linear_svm.fit(X, y)\n",
    "linear_svm.visualize_decision_boundary(X, y)\n",
    "\n",
    "# Polynomial kernel (degree=2)\n",
    "poly_svm = ScratchSVMClassifier(kernel='poly', degree=2, verbose=True)\n",
    "poly_svm.fit(X, y)\n",
    "poly_svm.visualize_decision_boundary(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
