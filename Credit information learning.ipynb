{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What to learn and predict?\n",
    "\n",
    "Learn patterns from historical loan application data to predict whether applicants will repay loans or default\n",
    "\n",
    "Predict probability (0-1) of repayment difficulty for each applicant (binary classification)\n",
    "\n",
    "2. Submission file requirements:\n",
    "\n",
    "CSV file with exactly two columns:\n",
    "\n",
    "SK_ID_CURR (application ID)\n",
    "\n",
    "TARGET (predicted probability of default)\n",
    "\n",
    "File name should be \"submission.csv\"\n",
    "\n",
    "3. Evaluation metric:\n",
    "\n",
    "AUC-ROC (Area Under the Receiver Operating Characteristic Curve)\n",
    "\n",
    "Measures how well model distinguishes defaulters from non-defaulters\n",
    "\n",
    "Range: 0.5 (random guessing) to 1.0 (perfect prediction)\n",
    "\n",
    "Higher values indicate better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Loading training data\n",
    "train = pd.read_csv(r\"C:\\Users\\Admin\\Downloads\\application_train.csv.zip\")\n",
    "test = pd.read_csv(r\"C:\\Users\\Admin\\Downloads\\application_test.csv.zip\")\n",
    "\n",
    "#basic info\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n",
    "print(\"\\nTarget distribution (1=Default, 0=Repaid):\")\n",
    "print(train['TARGET'].value_counts(normalize=True))\n",
    "\n",
    "# Selecting numerical features\n",
    "numerical_features = train.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_features = numerical_features.drop(['SK_ID_CURR', 'TARGET'])  # Remove ID & target\n",
    "\n",
    "# Imputing missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train = imputer.fit_transform(train[numerical_features])\n",
    "y_train = train['TARGET']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "#\n",
    "X_test = imputer.transform(test[numerical_features])\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Splittting into train/validation (80-20 split)\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Training Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Prediction on validation set\n",
    "y_val_pred = model.predict_proba(X_val_split)[:, 1]  # Probabilities for class 1 (default)\n",
    "\n",
    "# Evaluating using AUC-ROC\n",
    "auc_score = roc_auc_score(y_val_split, y_val_pred)\n",
    "print(f\"Validation AUC: {auc_score:.4f}\")\n",
    "\n",
    "# Prediction on test data\n",
    "test_preds = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Creating submission file\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "    'TARGET': test_preds\n",
    "})\n",
    "\n",
    "# Saving to CSV\n",
    "submission.to_csv('submission_baseline.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Loading the data\n",
    "train = pd.read_csv(r\"C:\\Users\\Admin\\Downloads\\application_train.csv.zip\")\n",
    "test = pd.read_csv(r\"C:\\Users\\Admin\\Downloads\\application_test.csv.zip\")\n",
    "\n",
    "# Preprocessing\n",
    "# Selected numerical features only for simplicity\n",
    "numerical_cols = train.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_features = [col for col in numerical_cols if col not in ['SK_ID_CURR', 'TARGET']]\n",
    "\n",
    "# Handling missing values (median imputation)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train = imputer.fit_transform(train[numerical_features])\n",
    "y_train = train['TARGET']\n",
    "X_test = imputer.transform(test[numerical_features])\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Training final model on ALL training data \n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predictions (probabilities for class 1)\n",
    "test_preds = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Creating submission file\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "    'TARGET': test_preds\n",
    "})\n",
    "\n",
    "# Saving to CSV\n",
    "submission.to_csv('submission_logreg_baseline.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# Loading data\n",
    "train = pd.read_csv(r\"C:\\Users\\Admin\\Downloads\\application_train.csv.zip\")\n",
    "test = pd.read_csv(r\"C:\\Users\\Admin\\Downloads\\application_test.csv.zip\")\n",
    "\n",
    "#common preprocessing\n",
    "num_features = train.select_dtypes(include=['int64','float64']).columns.drop(['SK_ID_CURR','TARGET'])\n",
    "cat_features = train.select_dtypes(include=['object']).columns\n",
    "y = train['TARGET']\n",
    "\n",
    "#preprocessing \n",
    "imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "\n",
    "X = imputer.fit_transform(train[num_features])\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "val_pred = model.predict_proba(X_val)[:,1]\n",
    "print(f\"Baseline AUC: {roc_auc_score(y_val, val_pred):.4f}\")\n",
    "\n",
    "#ratio features\n",
    "for df in [train, test]:\n",
    "    df['INCOME_CREDIT_RATIO'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['ANNUITY_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "    df['EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "\n",
    "features = num_features.tolist() + [\n",
    "    'INCOME_CREDIT_RATIO', \n",
    "    'ANNUITY_INCOME_RATIO',\n",
    "    'CREDIT_TO_ANNUITY_RATIO',\n",
    "    'EMPLOYED_TO_BIRTH_RATIO'\n",
    "]\n",
    "\n",
    "X = imputer.fit_transform(train[features])\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "val_pred = model.predict_proba(X_val)[:,1]\n",
    "print(f\"Ratio Features AUC: {roc_auc_score(y_val, val_pred):.4f}\")\n",
    "\n",
    "# Preprocessing numerical and categorical separately\n",
    "X_num = imputer.fit_transform(train[num_features])\n",
    "X_num = scaler.fit_transform(X_num)\n",
    "X_cat = encoder.fit_transform(train[cat_features])\n",
    "\n",
    "# Combine numerical and categorical\n",
    "X = hstack([csr_matrix(X_num), X_cat])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "val_pred = model.predict_proba(X_val)[:,1]\n",
    "print(f\"Categorical Encoding AUC: {roc_auc_score(y_val, val_pred):.4f}\")\n",
    "\n",
    "#merging bureau data\n",
    "bureau = pd.read_csv(r\"C:\\Users\\Admin\\Downloads\\bureau.csv.zip\")\n",
    "bureau_agg = bureau.groupby('SK_ID_CURR').agg({\n",
    "    'DAYS_CREDIT': ['min','max','mean'],\n",
    "    'AMT_CREDIT_SUM': ['sum']\n",
    "})\n",
    "bureau_agg.columns = ['BURO_'+'_'.join(col).upper() for col in bureau_agg.columns]\n",
    "\n",
    "train = train.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
    "test = test.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
    "\n",
    "#new features\n",
    "features += bureau_agg.columns.tolist()\n",
    "\n",
    "X = imputer.fit_transform(train[features])\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "val_pred = model.predict_proba(X_val)[:,1]\n",
    "print(f\"External Data AUC: {roc_auc_score(y_val, val_pred):.4f}\")\n",
    "\n",
    "# Feature selection\n",
    "final_features = [\n",
    "    'EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3',\n",
    "    'AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY',\n",
    "    'CREDIT_TO_ANNUITY_RATIO','EMPLOYED_TO_BIRTH_RATIO',\n",
    "    'BURO_DAYS_CREDIT_MEAN','BURO_AMT_CREDIT_SUM_SUM'\n",
    "]\n",
    "\n",
    "X = imputer.fit_transform(train[final_features])\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "val_pred = model.predict_proba(X_val)[:,1]\n",
    "print(f\"XGBoost AUC: {roc_auc_score(y_val, val_pred):.4f}\")\n",
    "\n",
    "#submission\n",
    "test_X = imputer.transform(test[final_features])\n",
    "test_X = scaler.transform(test_X)\n",
    "test_preds = model.predict_proba(test_X)[:,1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "    'TARGET': test_preds\n",
    "})\n",
    "submission.to_csv('best_submission.csv', index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
